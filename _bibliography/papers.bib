---
---

@article{munier:hal-03811028,
  TITLE = {{The MLE is a reliable source: sharp performance guarantees for localization problems}},
  AUTHOR = {Munier, Nathana{\"e}l and Soubies, Emmanuel and Weiss, Pierre},
  URL = {https://hal.science/hal-03811028},
  JOURNAL = {{Inverse Problems}},
  PUBLISHER = {{IOP Publishing}},
  YEAR = {2023},
  MONTH = Nov,
  DOI = {10.1088/1361-6420/ad0dbb},
  PDF = {https://hal.science/hal-03811028v2/file/Paper.pdf},
  HAL_ID = {hal-03811028},
  abstract = {Single source localization from low-pass filtered measurements is ubiquitous in optics, wireless communications 
  and sound processing. We analyze the performance of the maximum likelihood estimator (MLE) in this context with additive 
  white Gaussian noise. We derive necessary conditions and sufficient conditions on the maximum admissible noise level to 
  reach a given precision with high probability. The two conditions match closely, with a discrepancy related to the 
  conditioning of a noiseless cost function. They tightly surround the Cramér–Rao lower bound for low noise levels. 
  However, they are significantly more precise to describe the performance of the MLE for larger levels. As an outcome, 
  we obtain a new criterion for the design of point spread functions in single molecule microscopy.}
}


@article{munier2023sandpilegroupssupersingularisogeny,
 URL = {https://www.jstor.org/stable/48766118},
 abstract = {Let p and q be distinct primes, and let Xp,q be the (q + 1)-
regular graph whose nodes are supersingular elliptic curves over Fp and whose
edges are q-isogenies. For fixed p, we compute the distribution of the ℓ-Sylow
subgroup of the sandpile group (i.e. Jacobian) of Xp,q as q → ∞. We find that
the distribution disagrees with the Cohen–Lenstra heuristic in this context.
Our proof is via Galois representations attached to modular curves. As a
corollary, we give an upper bound on the probability that the Jacobian is
cyclic, which we conjecture to be sharp.},
 author = {Nathanaël MUNIER and Ari SHNIDMAN},
 journal = {Journal de Théorie des Nombres de Bordeaux},
 number = {3},
 pages = {pp. 751--774},
 publisher = {Société Arithmétique de Bordeaux},
 title = {Sandpile groups of supersingular isogeny graphs},
 volume = {35},
 year = {2023},
 PDF = {https://arxiv.org/pdf/2111.10389},
 preview = {assets/img/Sandpile_group.webp}
}


@inproceedings{cazorla2023sketchpose,
  title={Sketchpose: Learning to Segment Cells with Partial Annotations},
  author={Cazorla, Cl{\'e}ment and Munier, Nathana{\"e}l and Morin, Renaud and Weiss, Pierre},
  year={2023},
  PDF = {https://hal.science/hal-04330824v1/file/sketchpose_hal.pdf},
  abstract = {A few neural networks in biological image segmentation rely on a prediction of a distance map. This principle is 
  at the basis of popular software such as Stardist, Cellpose or Omnipose. It yields unprecedented accuracy but hinges on fully 
  annotated datasets. This can be a serious limitation for generating training sets and performing transfer learning. In this 
  paper, we show how to handle partial annotation, while still relying on the distance map. We design a variant of the Omnipose 
  architecture embedded in a user-friendly Napari plugin. We evaluate the performance of the proposed approach in the contexts 
  of frugal learning, transfer learning and regular learning on a large database. Our experiments show that the proposed approach 
  can lead to substantial savings in time and resources without sacrificing segmentation quality.},
  preview = {assets/img/Sketchpose.png}
}


@inproceedings{munier2023algorithmes,
  TITLE = {{Algorithmes de visualisation de non-identifiabilit{\'e}}},
  AUTHOR = {Munier, Nathana{\"e}l and Soubies, Emmanuel and Weiss, Pierre},
  URL = {https://hal.science/hal-04138308},
  BOOKTITLE = {{XXIX{\`e}me Colloque Francophone de Traitement du Signal et des Images (GRETSI 2023)}},
  YEAR = {2023},
  MONTH = Aug,
  PDF = {https://hal.science/hal-04138308v1/file/gretsi.pdf},
  HAL_ID = {hal-04138308},
  abstract = {The identification of a set of parameters x from observed data y is often reduced to the resolution of a problem of
the type Φ(x) = y, where Φ is a continuous application. This equation appears in domains such as (blind) inverse problems, data
assimilation, or optimal control. When the solution is not unique, it may be important to inform the user about the set of plausible
solutions. We propose here an algorithm to locally describe a set of solutions of this equation. It is essentially based on automatic
differentiation and on a local parameterization of the solution manifold. We illustrate the interest of this approach on two toy
examples.}
}


@inproceedings{munier2024jackpot,
  title={Jackpot: Approximating Uncertainty Domains
with Adversarial Manifolds},
  author={Munier, Nathana{\"e}l and Soubies, Emmanuel and Weiss, Pierre},
  year={2024},
  PDF = {https://hal.science/hal-04744486v1/document},
  abstract = {Given a forward mapping Φ : RN → RM , the region {x ∈ RN , ∥Φ(x) −
y∥2 ≤ ε}, where y ∈ RM is a given vector and ε ≥ 0 is a perturbation am-
plitude, represents the set of all possible inputs x that could have produced
the measurement y within an acceptable error margin. This set reflects
the inherent uncertainty or indeterminacy in recovering the true input x
solely from the noisy observation y, which is a key challenge in inverse
problems. In this work, we develop a numerical algorithm called Jackpot
(Jacobian Kernel Projection Optimization) which approximates this set
with a low-dimensional adversarial manifold. The proposed algorithm
leverages automatic differentation, allowing it to handle complex, high
dimensional mappings such as those found when dealing with dynamical
systems or neural networks. We demonstrate the effectiveness of our al-
gorithm on various challenging large-scale, non-linear problems including
parameter identification in dynamical systems and blind image deblurring.
The algorithm is integrated within the Python package deepinv.}
}


@article{munier2024exploring,
  title={Exploring instabilities of inverse problem solvers with low-dimensional manifolds},
  author={Munier, Nathana{\"e}l and Soubies, Emmanuel and Weiss, Pierre},
  year={2024},
  MONTH = Oct,
  PDF = {https://hal.science/hal-04753218/document},
  abstract = {Inverse problem solvers are mappings S : Y → X , where Y is the space
of measurements and X the space of signals we wish to recover. We propose a
simple algorithm to visualize the main instability of a solver implemented within
an automatic differentiation framework. We justify it through simple considerations
and illustrate its behavior on a deconvolution problem solved with a neural network
based reconstruction method. The proposed algorithm can be used to provide addi-
tional insights on the properties of inverse problem solvers, and can be viewed as a
simple uncertainty quantification technique.}
}

