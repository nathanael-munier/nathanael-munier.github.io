---
---

@article{munier:hal-03811028,
  TITLE = {{The MLE is a reliable source: sharp performance guarantees for localization problems}},
  AUTHOR = {Munier, Nathana{\"e}l and Soubies, Emmanuel and Weiss, Pierre},
  URL = {https://hal.science/hal-03811028},
  JOURNAL = {{Inverse Problems}},
  PUBLISHER = {{IOP Publishing}},
  YEAR = {2023},
  MONTH = Nov,
  DOI = {10.1088/1361-6420/ad0dbb},
  PDF = {https://hal.science/hal-03811028v2/file/Paper.pdf},
  HAL_ID = {hal-03811028},
  abstract = {Single source localization from low-pass filtered measurements is ubiquitous in optics, wireless communications 
  and sound processing. We analyze the performance of the maximum likelihood estimator (MLE) in this context with additive 
  white Gaussian noise. We derive necessary conditions and sufficient conditions on the maximum admissible noise level to 
  reach a given precision with high probability. The two conditions match closely, with a discrepancy related to the 
  conditioning of a noiseless cost function. They tightly surround the Cram√©r‚ÄìRao lower bound for low noise levels. 
  However, they are significantly more precise to describe the performance of the MLE for larger levels. As an outcome, 
  we obtain a new criterion for the design of point spread functions in single molecule microscopy.}
}


@article{munier2021sandpilegroupssupersingularisogeny,
 URL = {https://www.jstor.org/stable/48766118},
 abstract = {Soient p et q deux nombres premiers distincts, et soit Xp, q le graphe (q + 1)-r√©gulier 
 dont les n≈ìuds sont les courbes elliptiques supersinguli√®res sur ùîΩÃÑp et dont les ar√™tes sont les q-isog√©nies. 
 Pour une valeur de p fix√©e, la distribution des sous-groupes de ‚Ñì-Sylow du groupe jacobien de Xp, q est 
 donn√©e pour q ‚Üí ‚àû. Nous constatons que cette distribution ne correspond pas √† l‚Äôheuristique de Cohen‚ÄìLenstra 
 dans ce contexte. La preuve que nous donnons utilise des repr√©sentations de Galois reli√©es √† des courbes 
 modulaires. Comme corollaire, nous donnons une borne sup√©rieure sur la probabilit√© que le groupe jacobien 
 soit cyclique, que nous conjecturons √™tre optimale. Let p and q be distinct primes, and let Xp, q be the 
 (q + 1)-regular graph whose nodes are supersingular elliptic curves over ùîΩÃÑp and whose edges are q-isogenies. 
 For fixed p, we compute the distribution of the l-Sylow subgroup of the sandpile group (i.e. Jacobian) of 
 Xp, q as q‚Üí ‚àû. We find that the distribution disagrees with the Cohen‚ÄìLenstra heuristic in this context. 
 Our proof is via Galois representations attached to modular curves. As a corollary, we give an upper bound 
 on the probability that the Jacobian is cyclic, which we conjecture to be sharp.},
 author = {Nathana√´l MUNIER and Ari SHNIDMAN},
 journal = {Journal de Th√©orie des Nombres de Bordeaux},
 number = {3},
 pages = {pp. 751--774},
 publisher = {Soci√©t√© Arithm√©tique de Bordeaux},
 title = {Sandpile groups of supersingular isogeny graphs},
 volume = {35},
 year = {2023},
 PDF = {https://arxiv.org/pdf/2111.10389}
}


@inproceedings{cazorla2023sketchpose,
  title={Sketchpose: Learning to Segment Cells with Partial Annotations},
  author={Cazorla, Cl{\'e}ment and Munier, Nathana{\"e}l and Morin, Renaud and Weiss, Pierre},
  year={2023},
  PDF = {https://hal.science/hal-04330824v1/file/sketchpose_hal.pdf},
  abstract = {A few neural networks in biological image segmentation rely on a prediction of a distance map. This principle is 
  at the basis of popular software such as Stardist, Cellpose or Omnipose. It yields unprecedented accuracy but hinges on fully 
  annotated datasets. This can be a serious limitation for generating training sets and performing transfer learning. In this 
  paper, we show how to handle partial annotation, while still relying on the distance map. We design a variant of the Omnipose 
  architecture embedded in a user-friendly Napari plugin. We evaluate the performance of the proposed approach in the contexts 
  of frugal learning, transfer learning and regular learning on a large database. Our experiments show that the proposed approach 
  can lead to substantial savings in time and resources without sacrificing segmentation quality.}
}


@inproceedings{munier2023algorithmes,
  TITLE = {{Algorithmes de visualisation de non-identifiabilit{\'e}}},
  AUTHOR = {Munier, Nathana{\"e}l and Soubies, Emmanuel and Weiss, Pierre},
  URL = {https://hal.science/hal-04138308},
  BOOKTITLE = {{XXIX{\`e}me Colloque Francophone de Traitement du Signal et des Images (GRETSI 2023)}},
  YEAR = {2023},
  MONTH = Aug,
  PDF = {https://hal.science/hal-04138308v1/file/gretsi.pdf},
  HAL_ID = {hal-04138308},
  abstract = {L'identification d'un ensemble de param√®tres $$x$$ √† partir de donn√©es observ√©es $$y$$ est souvent r√©duite √† la r√©solution 
  d'un probl√®me du type $$f(x) = y$$, o√π $$f$$ est une application continue. Cette √©quation appara√Æt dans des domaines tels que les 
  probl√®mes inverses (aveugles), l'assimilation de donn√©es ou encore le contr√¥le optimal. Lorsque la solution n'est pas unique, il 
  peut √™tre important d'en informer l'utilisateur et de le renseigner sur l'ensemble des solutions plausibles. Nous proposons ici un 
  algorithme permettant de d√©crire localement un ensemble de solutions de cette √©quation. Il repose essentiellement sur la diff√©rentiation 
  automatique et sur une param√©trisation locale de la vari√©t√© des solutions. Nous illustrons l'int√©r√™t de cette approche sur deux exemples jouets.}
}


@inproceedings{munier2024jackpot,
  title={Jackpot: Approximating Uncertainty Domains
with Adversarial Manifolds},
  author={Munier, Nathana{\"e}l and Soubies, Emmanuel and Weiss, Pierre},
  year={2024},
  PDF = {https://hal.science/hal-04744486v1/document},
  abstract = {Given a forward mapping Œ¶ : RN ‚Üí RM , the region {x ‚àà RN , ‚à•Œ¶(x) ‚àí
y‚à•2 ‚â§ Œµ}, where y ‚àà RM is a given vector and Œµ ‚â• 0 is a perturbation am-
plitude, represents the set of all possible inputs x that could have produced
the measurement y within an acceptable error margin. This set reflects
the inherent uncertainty or indeterminacy in recovering the true input x
solely from the noisy observation y, which is a key challenge in inverse
problems. In this work, we develop a numerical algorithm called Jackpot
(Jacobian Kernel Projection Optimization) which approximates this set
with a low-dimensional adversarial manifold. The proposed algorithm
leverages automatic differentation, allowing it to handle complex, high
dimensional mappings such as those found when dealing with dynamical
systems or neural networks. We demonstrate the effectiveness of our al-
gorithm on various challenging large-scale, non-linear problems including
parameter identification in dynamical systems and blind image deblurring.
The algorithm is integrated within the Python package deepinv.}
}


@article{munier2024exploring,
  title={Exploring instabilities of inverse problem solvers with low-dimensional manifolds},
  author={Munier, Nathana{\"e}l and Soubies, Emmanuel and Weiss, Pierre},
  year={2024},
  MONTH = Oct,
  PDF = {https://hal.science/hal-04753218/document},
  abstract = {Inverse problem solvers are mappings S : Y ‚Üí X , where Y is the space
of measurements and X the space of signals we wish to recover. We propose a
simple algorithm to visualize the main instability of a solver implemented within
an automatic differentiation framework. We justify it through simple considerations
and illustrate its behavior on a deconvolution problem solved with a neural network
based reconstruction method. The proposed algorithm can be used to provide addi-
tional insights on the properties of inverse problem solvers, and can be viewed as a
simple uncertainty quantification technique.}
}

